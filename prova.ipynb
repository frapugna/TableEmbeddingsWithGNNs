{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(r\"C:\\Users\\frapu\\Desktop\\TableEmbeddingsWithGNNs\\Datasets\\testAB.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 2)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(axis=1,how='all', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 2)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    Luca_rossi the boss 92\n",
       "B                      23.0\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    Mario\n",
       "B    345.0\n",
       "Name: 1, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "A    Valerio\n",
       "B        NaN\n",
       "Name: 3, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df\u001b[39m.\u001b[39miloc[\u001b[39m3\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\frapu\\Anaconda3\\envs\\HPIMaster\\Lib\\site-packages\\pandas\\core\\indexing.py:1103\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1100\u001b[0m axis \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxis \u001b[39mor\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[0;32m   1102\u001b[0m maybe_callable \u001b[39m=\u001b[39m com\u001b[39m.\u001b[39mapply_if_callable(key, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj)\n\u001b[1;32m-> 1103\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_axis(maybe_callable, axis\u001b[39m=\u001b[39maxis)\n",
      "File \u001b[1;32mc:\\Users\\frapu\\Anaconda3\\envs\\HPIMaster\\Lib\\site-packages\\pandas\\core\\indexing.py:1656\u001b[0m, in \u001b[0;36m_iLocIndexer._getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1653\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCannot index by location index with a non-integer key\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m   1655\u001b[0m \u001b[39m# validate the location\u001b[39;00m\n\u001b[1;32m-> 1656\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_integer(key, axis)\n\u001b[0;32m   1658\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_ixs(key, axis\u001b[39m=\u001b[39maxis)\n",
      "File \u001b[1;32mc:\\Users\\frapu\\Anaconda3\\envs\\HPIMaster\\Lib\\site-packages\\pandas\\core\\indexing.py:1589\u001b[0m, in \u001b[0;36m_iLocIndexer._validate_integer\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1587\u001b[0m len_axis \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mobj\u001b[39m.\u001b[39m_get_axis(axis))\n\u001b[0;32m   1588\u001b[0m \u001b[39mif\u001b[39;00m key \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m len_axis \u001b[39mor\u001b[39;00m key \u001b[39m<\u001b[39m \u001b[39m-\u001b[39mlen_axis:\n\u001b[1;32m-> 1589\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mIndexError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39msingle positional indexer is out-of-bounds\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mIndexError\u001b[0m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "df.iloc[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = [0,1,2]\n",
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l[0:512]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = [i for i in range(2048)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2047"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "511"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(l[0:512])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\frapu\\Anaconda3\\envs\\HPIMaster\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from embeddings import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\frapu\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph generation starts\n",
      "Row: 0/3\n",
      "t_exec: 1.822990894317627s\n",
      "number of embeddings: 10\n",
      "Graph generation starts\n",
      "Row: 0/864\n",
      "Row: 100/864\n",
      "Row: 200/864\n",
      "Row: 300/864\n",
      "Row: 400/864\n",
      "Row: 500/864\n",
      "Row: 600/864\n",
      "Row: 700/864\n",
      "Row: 800/864\n",
      "t_exec: 2.6639578342437744s\n",
      "number of embeddings: 6053\n"
     ]
    }
   ],
   "source": [
    "df1 = pd.read_csv(r\"C:\\Users\\frapu\\Desktop\\TableEmbeddingsWithGNNs\\Datasets\\testAB.csv\")\n",
    "#df = pd.read_csv(r\"C:\\Users\\frapu\\Desktop\\TableEmbeddingsWithGNNs\\Datasets\\walmart_amazon-tableB.csv\")\n",
    "print('Starting')\n",
    "df2 = pd.read_csv(r\"C:\\Users\\frapu\\Desktop\\TableEmbeddingsWithGNNs\\Datasets\\fodors_zagats-master.csv\")\n",
    "bert_embedding_generator = Bert_Embedding_Buffer()\n",
    "string_token_preprocessor = String_token_preprocessor()\n",
    "print('Graph generation starts')\n",
    "start = time.time()\n",
    "g1 = Graph(df1, 'Table', bert_embedding_generator, string_token_preprocessor)\n",
    "\n",
    "end = time.time()\n",
    "print(f't_exec: {end-start}s')\n",
    "print(f'number of embeddings: {g1.X.shape[0]}')\n",
    "print('Graph generation starts')\n",
    "start = time.time()\n",
    "g2 = Graph(df2, 'Table', bert_embedding_generator, string_token_preprocessor)\n",
    "end = time.time()\n",
    "print(f't_exec: {end-start}s')\n",
    "print(f'number of embeddings: {g2.X.shape[0]}')\n",
    "\n",
    "gl = Graph_list()\n",
    "gl.add_item(g1)\n",
    "gl.add_item(g2)\n",
    "gl.save(r\"C:\\Users\\frapu\\Desktop\\TableEmbeddingsWithGNNs\\Tests\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty sample_list created\n"
     ]
    }
   ],
   "source": [
    "gd = GraphDataset(directory_name=r\"C:\\Users\\frapu\\Desktop\\TableEmbeddingsWithGNNs\\Tests\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd.add_item((0,1,0.3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = gd[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = EmbeddingGenerator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e(s[0].X,s[0].edges).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e(s[1].X,s[1].edges).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class test:\n",
    "    def test():\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'test' object has no attribute 'prova'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m t\u001b[39m.\u001b[39mprova\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'test' object has no attribute 'prova'"
     ]
    }
   ],
   "source": [
    "t.prova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    not(t.prova)\n",
    "except:\n",
    "    print('updated prova')\n",
    "    t.prova=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = api.load('fasttext-wiki-news-subwords-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(model['may'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5386, 0.8531, 0.6390, 0.0187, 0.0480, 0.8659, 0.5062, 0.9115, 0.9067,\n",
       "        0.7758, 0.5354, 0.0296, 0.8004, 0.1584, 0.3994, 0.9848, 0.5778, 0.2977,\n",
       "        0.9672, 0.7102, 0.7066, 0.3659, 0.0319, 0.6083, 0.0279, 0.7886, 0.2789,\n",
       "        0.4406, 0.2790, 0.5384, 0.7354, 0.0679, 0.7561, 0.5447, 0.9265, 0.3675,\n",
       "        0.5519, 0.4432, 0.7307, 0.3088, 0.2435, 0.8187, 0.7165, 0.5511, 0.7885,\n",
       "        0.0305, 0.0874, 0.2149, 0.3073, 0.5008, 0.5511, 0.5354, 0.4967, 0.2741,\n",
       "        0.8523, 0.3856, 0.7732, 0.4448, 0.2872, 0.1715, 0.2130, 0.4620, 0.0399,\n",
       "        0.3646, 0.2183, 0.1975, 0.8104, 0.9964, 0.9622, 0.0178, 0.3510, 0.4774,\n",
       "        0.0062, 0.0074, 0.0309, 0.3019, 0.6122, 0.6209, 0.7348, 0.9019, 0.9303,\n",
       "        0.3495, 0.7801, 0.1442, 0.1083, 0.9036, 0.7426, 0.6838, 0.7354, 0.5639,\n",
       "        0.4512, 0.3233, 0.2404, 0.0555, 0.2883, 0.4828, 0.8138, 0.1792, 0.6381,\n",
       "        0.9246])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([300])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(model['may']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\frapu\\Anaconda3\\envs\\HPIMaster\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from node_embeddings import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading fasttext model, it will take 2/3 minutes\n",
      "Model loaded\n"
     ]
    }
   ],
   "source": [
    "gen = FasttextEmbeddingBuffer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = \"cat dog duck luck\"\n",
    "gen('cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen.n_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen.n_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = gen.pop_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 300])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[56], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m gen\u001b[39m.\u001b[39membeddings\u001b[39m.\u001b[39mshape\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "gen.embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([inf, -inf, inf, -inf, -inf, inf, inf, -inf, inf, inf, -inf, -inf, inf, -inf, -inf, inf, inf, -inf, inf, -inf, inf, -inf, inf, inf,\n",
       "        inf, -inf, inf, inf, inf, inf, -inf, -inf, inf, inf, -inf, -inf, inf, -inf, -inf, -inf, inf, -inf, -inf, -inf, inf, inf, inf, inf,\n",
       "        inf, -inf, inf, inf, inf, -inf, inf, -inf, -inf, inf, -inf, inf, -inf, -inf, inf, -inf, inf, inf, -inf, inf, -inf, -inf, inf, inf,\n",
       "        inf, -inf, inf, inf, -inf, -inf, inf, -inf, inf, -inf, inf, inf, inf, -inf, -inf, inf, inf, inf, -inf, inf, -inf, -inf, inf, inf,\n",
       "        inf, inf, inf, inf, inf, inf, inf, inf, -inf, -inf, -inf, inf, -inf, -inf, -inf, inf, inf, -inf, -inf, -inf, inf, inf, -inf, inf,\n",
       "        -inf, inf, inf, -inf, inf, inf, -inf, -inf, -inf, inf, -inf, -inf, -inf, inf, -inf, -inf, -inf, inf, inf, -inf, -inf, inf, inf, -inf,\n",
       "        -inf, -inf, inf, -inf, -inf, -inf, -inf, inf, inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, -inf, inf, -inf, inf, -inf, -inf, inf, inf,\n",
       "        -inf, -inf, -inf, inf, -inf, inf, -inf, inf, -inf, inf, inf, inf, inf, -inf, inf, -inf, inf, -inf, inf, inf, -inf, -inf, -inf, inf,\n",
       "        -inf, -inf, -inf, inf, -inf, inf, -inf, inf, -inf, inf, -inf, -inf, inf, -inf, inf, -inf, -inf, -inf, inf, -inf, -inf, -inf, -inf, inf,\n",
       "        inf, -inf, inf, inf, inf, inf, -inf, inf, inf, inf, -inf, inf, inf, -inf, -inf, -inf, -inf, -inf, inf, -inf, inf, inf, -inf, -inf,\n",
       "        inf, -inf, inf, -inf, inf, inf, inf, inf, -inf, -inf, inf, -inf, -inf, inf, inf, -inf, inf, -inf, inf, inf, -inf, -inf, inf, -inf,\n",
       "        -inf, -inf, -inf, inf, inf, inf, -inf, inf, -inf, -inf, inf, -inf, inf, -inf, inf, -inf, inf, inf, inf, -inf, -inf, inf, -inf, -inf,\n",
       "        -inf, inf, inf, inf, -inf, -inf, inf, inf, inf, inf, inf, inf])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen('lake blue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1417, -0.0665,  0.0294, -0.0054,  0.0601, -0.2388, -0.1346, -0.3108,\n",
       "         -0.0226,  0.0270,  0.0815, -0.1351,  0.0647, -0.0543, -0.0556, -0.0770,\n",
       "          0.1919, -0.0293,  0.0899, -0.0602,  0.0532, -0.0686, -0.0742,  0.1616,\n",
       "         -0.0191, -0.1480, -0.0375,  0.1188,  0.0025,  0.0875, -0.0206,  0.0963,\n",
       "          0.0830,  0.0317, -0.0097,  0.0113,  0.0815,  0.0515,  0.0598,  0.0118,\n",
       "          0.1208, -0.3760, -0.0151, -0.0722,  0.1138, -0.0071, -0.0098, -0.0303,\n",
       "         -0.0396,  0.2747, -0.0005,  0.0040,  0.0700,  0.0950, -0.1444, -0.1296,\n",
       "          0.1522, -0.0639, -0.1318, -0.0365, -0.0138, -0.0695,  0.2868, -0.1195,\n",
       "         -0.0341, -0.0855, -0.1497, -0.1588,  0.0115,  0.0369,  0.1636, -0.1241,\n",
       "          0.0337,  0.0477,  0.0704, -0.0366,  0.0050, -0.1107, -0.1432, -0.1101,\n",
       "         -0.0798, -0.1888,  0.0949,  0.0303, -0.0562,  0.1258,  0.0158, -0.0868,\n",
       "         -0.0796, -0.1936, -0.0888,  0.0519, -0.2570, -0.0208,  0.2252,  0.2885,\n",
       "          0.0712, -0.0280,  0.0143,  0.0812, -0.0595, -0.0133,  0.1332,  0.0175,\n",
       "          0.0863, -0.3846, -0.0755, -0.0623, -0.0162,  0.0044,  0.0765,  0.1422,\n",
       "          0.1478, -0.0657,  0.0786,  0.0278, -0.0194, -0.0909, -0.0850, -0.0179,\n",
       "         -0.0018,  0.1040,  0.0067, -0.2060,  0.0999, -0.0465,  0.0296, -0.2535,\n",
       "         -0.1664,  0.0903, -0.0637,  0.0218, -0.0063,  0.0398, -0.0679, -0.0013,\n",
       "          0.1402,  0.1781,  0.0308,  0.0361, -0.1551, -0.2240,  0.0594, -0.0030,\n",
       "          0.0442, -0.0185,  0.2056,  0.0909, -0.1136, -0.0789, -0.1157,  0.1342,\n",
       "          0.1465,  0.0065, -0.0636,  0.0033, -0.0442, -0.2266, -0.0694,  0.0425,\n",
       "         -0.0171, -0.0699, -0.0925,  0.0536, -0.0058,  0.1189,  0.1127, -0.0880,\n",
       "          0.0150,  0.1379, -0.0764, -0.1711, -0.1026, -0.0285,  0.1086,  0.1337,\n",
       "         -0.0637,  0.0455, -0.0806, -0.0658, -0.0097,  0.1084,  0.1255, -0.2217,\n",
       "         -0.0804, -0.0117, -0.1214,  0.2794,  0.0420, -0.0488,  0.0524,  0.0581,\n",
       "         -0.0805,  0.0142, -0.0036, -0.1258,  0.1608,  0.0550,  0.0021,  0.0633,\n",
       "         -0.4362,  0.1053, -0.2116, -0.1037, -0.0467,  0.0412, -0.0335,  0.0642,\n",
       "         -0.1754, -0.0622,  0.3930, -0.1698,  0.0496, -0.0205,  0.1643, -0.1917,\n",
       "         -0.0522,  0.0804,  0.1029, -0.1530,  0.0655, -0.0984, -0.2228,  0.2276,\n",
       "         -0.1348,  0.1287,  0.0138,  0.1132, -0.0101, -0.1174, -0.0796, -0.1100,\n",
       "         -0.1475,  0.1324, -0.0552,  0.0275,  0.1543,  0.0554, -0.1046, -0.0550,\n",
       "          0.2407,  0.1554, -0.1032, -0.1738, -0.0818, -0.0635,  0.0944,  0.1275,\n",
       "         -0.0424, -0.0942,  0.0511, -0.1080, -0.1046, -0.0206, -0.0552, -0.0422,\n",
       "         -0.1362, -0.0436,  0.1689, -0.0372, -0.0259,  0.0966,  0.0053, -0.1740,\n",
       "         -0.0863, -0.0301, -0.1378, -0.0831,  0.0949, -0.1108, -0.1146,  0.2423,\n",
       "         -0.2310, -0.1046,  0.1743, -0.2059, -0.0856,  0.0204,  0.1193, -0.0448,\n",
       "          0.2310, -0.1605,  0.0198,  0.1006, -0.1809, -0.0648, -0.0289, -0.0677,\n",
       "         -0.0141,  0.0927, -0.1742,  0.0553, -0.1206, -0.1297, -0.0283, -0.0342,\n",
       "          0.0841, -0.0094,  0.1371,  0.1149]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen.embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l\n",
      "u\n",
      "c\n",
      "a\n"
     ]
    }
   ],
   "source": [
    "for w in 'luca':\n",
    "    print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['luca']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'luca'.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(index=np.arange(0), columns=np.arange(8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[2][3] = 'luca'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=[[1,2,3,4,5,6], ['0asdlfkalsfdk','1','2','3','4','5']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0asdlfkalsfdk</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               0  1  2  3  4  5\n",
       "0              1  2  3  4  5  6\n",
       "1  0asdlfkalsfdk  1  2  3  4  5"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from smallDatasetGenerator import *\n",
    "tl = generateDatasetList(10, 10,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tl[\u001b[39m10\u001b[39;49m]\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "tl[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: '1',\n",
       " <function pandas.core.dtypes.missing.notna(obj: 'object') -> 'bool | npt.NDArray[np.bool_] | NDFrame'>: 8}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "dict = {1:'1'}\n",
    "dict[pd.notna] = 8\n",
    "dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict[pd.notna]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "nan",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mdict\u001b[39;49m[np\u001b[39m.\u001b[39;49mnan]\n",
      "\u001b[0;31mKeyError\u001b[0m: nan"
     ]
    }
   ],
   "source": [
    "dict[np.nan]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len('this sentence will be pretty long and hopefully it will confuse bert with a lot of useless words that are not only stop wrods but also other stuff and yws this sentence is pretty long again'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = ['I have a pen and an apple','this sentence will be pretty long and hopefully it will confuse bert with a lot of useless words that are not only stop wrods but also other stuff and yws this sentence is pretty long again',\n",
    "                  'cat', 'dog','Keanu Reeves is an actor 3', '4','1','2','3','4','5','6','7','8','9','0','I believe I can fly', 'The plot of the book is that it is a book', 'Leopard','JaGuar',\n",
    "                  'this sentence will be pretty long and hopefully it will confuse bert with a lot of useless words that are not only stop wrods but also other stuff and yws this sentence is pretty long again',\n",
    "                  'this sentence will be pretty long and hopefully it will confuse bert with a lot of useless words that are not only stop wrods but also other stuff and yws this sentence is pretty long again']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_sent = {}\n",
    "for s in sentences:\n",
    "    try:\n",
    "        len_sent[len(s.split())] += 1\n",
    "    except:\n",
    "        len_sent[len(s.split())] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{7: 1, 36: 3, 1: 15, 6: 1, 5: 1, 11: 1}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ciao ciao ciao ciao ciao ciao ciao ciao ciao ciao ciao ciao ciao ciao ciao ciao ciao ciao ciao ciao ciao ciao ciao ciao ciao ciao ciao ciao ciao ciao ciao ciao ciao ciao ciao ciao ciao ciao ciao ciao ']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[\"ciao \"*40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim.downloader as api\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = api.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['corpora', 'models'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = d['models'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fasttext-wiki-news-subwords-300\n"
     ]
    }
   ],
   "source": [
    "print (\"\\n\".join(s for s in l if 'fasttext' in s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['fasttext-wiki-news-subwords-300', 'conceptnet-numberbatch-17-06-300', 'word2vec-ruscorpora-300', 'word2vec-google-news-300', 'glove-wiki-gigaword-50', 'glove-wiki-gigaword-100', 'glove-wiki-gigaword-200', 'glove-wiki-gigaword-300', 'glove-twitter-25', 'glove-twitter-50', 'glove-twitter-100', 'glove-twitter-200', '__testing_word2vec-matrix-synopsis'])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.KeyedVectors at 0x7f7b28437350>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['fasttext-wiki-news-subwords-300', 'conceptnet-numberbatch-17-06-300', 'word2vec-ruscorpora-300', 'word2vec-google-news-300', 'glove-wiki-gigaword-50', 'glove-wiki-gigaword-100', 'glove-wiki-gigaword-200', 'glove-wiki-gigaword-300', 'glove-twitter-25', 'glove-twitter-50', 'glove-twitter-100', 'glove-twitter-200', '__testing_word2vec-matrix-synopsis'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_records': 3000000,\n",
       " 'file_size': 1743563840,\n",
       " 'base_dataset': 'Google News (about 100 billion words)',\n",
       " 'reader_code': 'https://github.com/RaRe-Technologies/gensim-data/releases/download/word2vec-google-news-300/__init__.py',\n",
       " 'license': 'not found',\n",
       " 'parameters': {'dimension': 300},\n",
       " 'description': \"Pre-trained vectors trained on a part of the Google News dataset (about 100 billion words). The model contains 300-dimensional vectors for 3 million words and phrases. The phrases were obtained using a simple data-driven approach described in 'Distributed Representations of Words and Phrases and their Compositionality' (https://code.google.com/archive/p/word2vec/).\",\n",
       " 'read_more': ['https://code.google.com/archive/p/word2vec/',\n",
       "  'https://arxiv.org/abs/1301.3781',\n",
       "  'https://arxiv.org/abs/1310.4546',\n",
       "  'https://www.microsoft.com/en-us/research/publication/linguistic-regularities-in-continuous-space-word-representations/?from=http%3A%2F%2Fresearch.microsoft.com%2Fpubs%2F189726%2Frvecs.pdf'],\n",
       " 'checksum': 'a5e5354d40acb95f9ec66d5977d140ef',\n",
       " 'file_name': 'word2vec-google-news-300.gz',\n",
       " 'parts': 1}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['models']['word2vec-google-news-300']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_records': 999999,\n",
       " 'file_size': 1005007116,\n",
       " 'base_dataset': 'Wikipedia 2017, UMBC webbase corpus and statmt.org news dataset (16B tokens)',\n",
       " 'reader_code': 'https://github.com/RaRe-Technologies/gensim-data/releases/download/fasttext-wiki-news-subwords-300/__init__.py',\n",
       " 'license': 'https://creativecommons.org/licenses/by-sa/3.0/',\n",
       " 'parameters': {'dimension': 300},\n",
       " 'description': '1 million word vectors trained on Wikipedia 2017, UMBC webbase corpus and statmt.org news dataset (16B tokens).',\n",
       " 'read_more': ['https://fasttext.cc/docs/en/english-vectors.html',\n",
       "  'https://arxiv.org/abs/1712.09405',\n",
       "  'https://arxiv.org/abs/1607.01759'],\n",
       " 'checksum': 'de2bb3a20c46ce65c9c131e1ad9a77af',\n",
       " 'file_name': 'fasttext-wiki-news-subwords-300.gz',\n",
       " 'parts': 1}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d['models']['fasttext-wiki-news-subwords-300']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap = api.load('fasttext-wiki-news-subwords-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "ap_vec = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Key 'giraffa' not present\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[42], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ap_vec[\u001b[39m'\u001b[39;49m\u001b[39mgiraffa\u001b[39;49m\u001b[39m'\u001b[39;49m]\n",
      "File \u001b[0;32m~/anaconda3/envs/HPIPyG/lib/python3.11/site-packages/gensim/models/keyedvectors.py:403\u001b[0m, in \u001b[0;36mKeyedVectors.__getitem__\u001b[0;34m(self, key_or_keys)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Get vector representation of `key_or_keys`.\u001b[39;00m\n\u001b[1;32m    390\u001b[0m \n\u001b[1;32m    391\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    400\u001b[0m \n\u001b[1;32m    401\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    402\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key_or_keys, _KEY_TYPES):\n\u001b[0;32m--> 403\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_vector(key_or_keys)\n\u001b[1;32m    405\u001b[0m \u001b[39mreturn\u001b[39;00m vstack([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_vector(key) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m key_or_keys])\n",
      "File \u001b[0;32m~/anaconda3/envs/HPIPyG/lib/python3.11/site-packages/gensim/models/keyedvectors.py:446\u001b[0m, in \u001b[0;36mKeyedVectors.get_vector\u001b[0;34m(self, key, norm)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_vector\u001b[39m(\u001b[39mself\u001b[39m, key, norm\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    423\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Get the key's vector, as a 1D numpy array.\u001b[39;00m\n\u001b[1;32m    424\u001b[0m \n\u001b[1;32m    425\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    444\u001b[0m \n\u001b[1;32m    445\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 446\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_index(key)\n\u001b[1;32m    447\u001b[0m     \u001b[39mif\u001b[39;00m norm:\n\u001b[1;32m    448\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfill_norms()\n",
      "File \u001b[0;32m~/anaconda3/envs/HPIPyG/lib/python3.11/site-packages/gensim/models/keyedvectors.py:420\u001b[0m, in \u001b[0;36mKeyedVectors.get_index\u001b[0;34m(self, key, default)\u001b[0m\n\u001b[1;32m    418\u001b[0m     \u001b[39mreturn\u001b[39;00m default\n\u001b[1;32m    419\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 420\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mKey \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00mkey\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m not present\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"Key 'giraffa' not present\""
     ]
    }
   ],
   "source": [
    "ap_vec['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list expected at most 1 argument, got 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mluca\u001b[39m(a:\u001b[39mint\u001b[39m, b:\u001b[39mfloat\u001b[39m, d:\u001b[39mlist\u001b[39;49m(\u001b[39m'\u001b[39;49m\u001b[39mmario\u001b[39;49m\u001b[39m'\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mroberto\u001b[39;49m\u001b[39m'\u001b[39;49m)):\n\u001b[1;32m      2\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00ma\u001b[39m}\u001b[39;00m\u001b[39m,\u001b[39m\u001b[39m{\u001b[39;00mb\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: list expected at most 1 argument, got 2"
     ]
    }
   ],
   "source": [
    "def luca(a:int, b:float, d:list('mario','roberto')):\n",
    "    print(f'{a},{b}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "luca() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m luca(\u001b[39m1\u001b[39;49m,\u001b[39m2\u001b[39;49m,\u001b[39m'\u001b[39;49m\u001b[39mvalerio\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "\u001b[0;31mTypeError\u001b[0m: luca() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "luca(1,2,'valerio')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<gensim.models.keyedvectors.KeyedVectors at 0x7f7bb548bf10>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ap_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gensim.models.keyedvectors.KeyedVectors"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ap_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'KeyedVectors' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ap_vec\u001b[39m.\u001b[39;49mshape\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyedVectors' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "ap_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ap_vec.vector_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([300])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(300).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from node_embeddings import *\n",
    "from graph import *\n",
    "from transformers import BertModel, BertTokenizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model = BertModel.from_pretrained('bert-base-uncased', output_hidden_states=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'BertModel' object has no attribute 'vector_size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49mvector_size\n",
      "File \u001b[0;32m~/anaconda3/envs/HPIPyG/lib/python3.11/site-packages/torch/nn/modules/module.py:1614\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1612\u001b[0m     \u001b[39mif\u001b[39;00m name \u001b[39min\u001b[39;00m modules:\n\u001b[1;32m   1613\u001b[0m         \u001b[39mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1614\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mAttributeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m object has no attribute \u001b[39m\u001b[39m'\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1615\u001b[0m     \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'BertModel' object has no attribute 'vector_size'"
     ]
    }
   ],
   "source": [
    "model.vector_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "HPIMaster",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
